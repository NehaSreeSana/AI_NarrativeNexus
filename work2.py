# -*- coding: utf-8 -*-
"""work2.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1aZlOBk6rcwytzA1vOshOJ5MRtrdY9Vp1
"""

# ------------------------------
# üîπ Full 20NG Processing in Colab
# ------------------------------

# Step 0: Mount Google Drive
from google.colab import drive
drive.mount('/content/drive')  # follow prompt to authenticate

# Step 1: Imports
import os
import pandas as pd
import re

# ------------------------------
# üîπ Step 1: Extract & Simple Clean
# ------------------------------
def extract_body(text):
    """Extract body of a 20NG post (basic clean)."""
    parts = re.split(r"\n\s*\n", text, maxsplit=1)
    body = parts[1] if len(parts) > 1 else parts[0]

    cleaned_lines = []
    for line in body.splitlines():
        if re.match(
            r"^(Archive-name|From|Subject|Path|Xref|Organization|Lines|Newsgroups|Message-ID|Keywords|Last-modified|Version):",
            line,
            re.I,
        ):
            continue
        if line.strip().startswith(">"):  # quoted text
            continue
        cleaned_lines.append(line)

    body_text = "\n".join(cleaned_lines).strip()
    body_text = re.sub(r"[\x00-\x08\x0B\x0C\x0E-\x1F]", "", body_text)
    return body_text

# ------------------------------
# üîπ Step 2: Deep Clean
# ------------------------------
def clean_body(raw_text):
    """Deep clean the body text only."""
    if pd.isna(raw_text):
        return ""

    parts = re.split(r"\n\s*\n", raw_text, maxsplit=1)
    body = parts[1] if len(parts) > 1 else parts[0]

    cleaned_lines = []
    for line in body.splitlines():
        if re.match(
            r"^(archive-name|from|subject|path|xref|organization|lines|newsgroups|message-id|keywords|last-modified|version):",
            line,
            re.I,
        ):
            continue
        if line.strip().startswith((">", "|")):
            continue
        if line.strip().startswith("--"):  # signature
            break
        if re.search(r"In article\s*<.*?>", line, re.I):
            continue
        if re.search(r"writes:|wrote:", line, re.I):
            continue
        cleaned_lines.append(line)

    body = "\n".join(cleaned_lines)

    # Remove emails, URLs, HTML tags
    body = re.sub(r"\S+@\S+", " ", body)
    body = re.sub(r"http\S+|www\.\S+", " ", body)
    body = re.sub(r"<[^>]+>", " ", body)

    # Remove phone numbers & large numbers
    body = re.sub(r"\+?\d[\d\-\(\)\s]{6,}\d", " ", body)  # phone-like
    body = re.sub(r"\b\d{7,}\b", " ", body)  # large numbers ‚â•7 digits

    # Remove non-alphanumeric except punctuation
    body = re.sub(r"[^a-zA-Z0-9\s\.\,\!\?]", " ", body)

    # Collapse multiple spaces/newlines
    body = re.sub(r"\n{2,}", "\n", body)
    body = re.sub(r"\s{2,}", " ", body)

    # Normalize
    body = body.lower().strip()
    body = re.sub(r"[\x00-\x08\x0B\x0C\x0E-\x1F]", "", body)
    return body

# ------------------------------
# üîπ Step 3: Main Pipeline
# ------------------------------
def convert_20ng(root_folder, output_excel, output_csv, max_files=150):
    data = []
    for category in sorted(os.listdir(root_folder)):
        category_path = os.path.join(root_folder, category)
        if os.path.isdir(category_path):
            print(f"üìÇ Processing category: {category}")
            for i, filename in enumerate(os.listdir(category_path)):
                if i >= max_files:
                    break
                file_path = os.path.join(category_path, filename)
                try:
                    with open(file_path, "r", encoding="latin1") as f:
                        raw_text = f.read()
                        body = extract_body(raw_text)
                        if body:
                            cleaned = clean_body(body)
                            data.append({
                                "filename": filename,
                                "category": category,
                                "text": cleaned
                            })
                except Exception as e:
                    print(f"‚ö†Ô∏è Skipping {file_path}: {e}")

    df = pd.DataFrame(data)

    # Save Excel
    df.to_excel(output_excel, index=False, engine="openpyxl")

    # Save CSV
    df.to_csv(output_csv, index=False, encoding="utf-8")

    print(f"‚úÖ Saved {len(df)} rows across {df['category'].nunique()} categories")
    print(f"   - Excel: {output_excel}")
    print(f"   - CSV:   {output_csv}")

# ------------------------------
# üîπ Step 4: Run
# ------------------------------
if __name__ == "__main__":
    convert_20ng(
        root_folder="/content/drive/MyDrive/req_data/20news-18828",  # <-- your Drive folder path
        output_excel="/content/drive/MyDrive/20news_18828_final_150.xlsx",
        output_csv="/content/drive/MyDrive/20news_18828_final_150.csv",
        max_files=150
    )